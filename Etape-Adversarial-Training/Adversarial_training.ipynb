{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textattack in c:\\users\\dell\\anaconda3\\lib\\site-packages (0.3.10)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\dell\\anaconda3\\lib\\site-packages (2.19.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\dell\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\dell\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\dell\\anaconda3\\lib\\site-packages (1.5.1)\n",
      "Requirement already satisfied: nltk in c:\\users\\dell\\anaconda3\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: bert-score>=0.3.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from textattack) (0.3.13)\n",
      "Requirement already satisfied: editdistance in c:\\users\\dell\\anaconda3\\lib\\site-packages (from textattack) (0.8.1)\n",
      "Requirement already satisfied: flair in c:\\users\\dell\\anaconda3\\lib\\site-packages (from textattack) (0.15.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\dell\\anaconda3\\lib\\site-packages (from textattack) (3.13.1)\n",
      "Requirement already satisfied: language-tool-python in c:\\users\\dell\\anaconda3\\lib\\site-packages (from textattack) (2.9.3)\n",
      "Requirement already satisfied: lemminflect in c:\\users\\dell\\anaconda3\\lib\\site-packages (from textattack) (0.2.3)\n",
      "Requirement already satisfied: lru-dict in c:\\users\\dell\\anaconda3\\lib\\site-packages (from textattack) (1.3.0)\n",
      "Requirement already satisfied: datasets>=2.4.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from textattack) (3.6.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from textattack) (1.13.1)\n",
      "Requirement already satisfied: torch!=1.8,>=1.7.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from textattack) (2.5.1)\n",
      "Requirement already satisfied: transformers>=4.30.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from textattack) (4.52.3)\n",
      "Requirement already satisfied: terminaltables in c:\\users\\dell\\anaconda3\\lib\\site-packages (from textattack) (3.1.10)\n",
      "Requirement already satisfied: tqdm in c:\\users\\dell\\anaconda3\\lib\\site-packages (from textattack) (4.66.5)\n",
      "Requirement already satisfied: word2number in c:\\users\\dell\\anaconda3\\lib\\site-packages (from textattack) (1.1)\n",
      "Requirement already satisfied: num2words in c:\\users\\dell\\anaconda3\\lib\\site-packages (from textattack) (0.5.14)\n",
      "Requirement already satisfied: more-itertools in c:\\users\\dell\\anaconda3\\lib\\site-packages (from textattack) (10.3.0)\n",
      "Requirement already satisfied: pinyin>=0.4.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from textattack) (0.4.0)\n",
      "Requirement already satisfied: jieba in c:\\users\\dell\\anaconda3\\lib\\site-packages (from textattack) (0.42.1)\n",
      "Requirement already satisfied: OpenHowNet in c:\\users\\dell\\anaconda3\\lib\\site-packages (from textattack) (2.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow) (1.71.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow) (3.9.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: click in c:\\users\\dell\\anaconda3\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from nltk) (2024.9.11)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\dell\\anaconda3\\lib\\site-packages (from bert-score>=0.3.5->textattack) (3.9.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from datasets>=2.4.0->textattack) (16.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from datasets>=2.4.0->textattack) (0.3.8)\n",
      "Requirement already satisfied: xxhash in c:\\users\\dell\\anaconda3\\lib\\site-packages (from datasets>=2.4.0->textattack) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from datasets>=2.4.0->textattack) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.4.0->textattack) (2024.6.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from datasets>=2.4.0->textattack) (0.31.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from datasets>=2.4.0->textattack) (6.0.1)\n",
      "Requirement already satisfied: rich in c:\\users\\dell\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\dell\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\dell\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from torch!=1.8,>=1.7.0->textattack) (1.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\dell\\anaconda3\\lib\\site-packages (from torch!=1.8,>=1.7.0->textattack) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from torch!=1.8,>=1.7.0->textattack) (3.1.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch!=1.8,>=1.7.0->textattack) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tqdm->textattack) (0.4.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from transformers>=4.30.0->textattack) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from transformers>=4.30.0->textattack) (0.5.3)\n",
      "Requirement already satisfied: boto3>=1.20.27 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from flair->textattack) (1.38.26)\n",
      "Requirement already satisfied: conllu<5.0.0,>=4.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from flair->textattack) (4.5.3)\n",
      "Requirement already satisfied: deprecated>=1.2.13 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from flair->textattack) (1.2.18)\n",
      "Requirement already satisfied: ftfy>=6.1.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from flair->textattack) (6.3.1)\n",
      "Requirement already satisfied: gdown>=4.4.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from flair->textattack) (5.2.0)\n",
      "Requirement already satisfied: langdetect>=1.0.9 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from flair->textattack) (1.0.9)\n",
      "Requirement already satisfied: lxml>=4.8.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from flair->textattack) (5.2.1)\n",
      "Requirement already satisfied: mpld3>=0.3 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from flair->textattack) (0.5.10)\n",
      "Requirement already satisfied: pptree>=3.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from flair->textattack) (3.1)\n",
      "Requirement already satisfied: pytorch-revgrad>=0.2.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from flair->textattack) (0.2.0)\n",
      "Requirement already satisfied: segtok>=1.5.11 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from flair->textattack) (1.5.11)\n",
      "Requirement already satisfied: sqlitedict>=2.0.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from flair->textattack) (2.1.0)\n",
      "Requirement already satisfied: tabulate>=0.8.10 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from flair->textattack) (0.9.0)\n",
      "Requirement already satisfied: transformer-smaller-training-vocab>=0.2.3 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from flair->textattack) (0.4.1)\n",
      "Requirement already satisfied: wikipedia-api>=0.5.7 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from flair->textattack) (0.8.1)\n",
      "Requirement already satisfied: bioc<3.0.0,>=2.0.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from flair->textattack) (2.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\dell\\anaconda3\\lib\\site-packages (from language-tool-python->textattack) (5.9.0)\n",
      "Requirement already satisfied: toml in c:\\users\\dell\\anaconda3\\lib\\site-packages (from language-tool-python->textattack) (0.10.2)\n",
      "Requirement already satisfied: docopt>=0.6.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from num2words->textattack) (0.6.2)\n",
      "Requirement already satisfied: anytree in c:\\users\\dell\\anaconda3\\lib\\site-packages (from OpenHowNet->textattack) (2.13.0)\n",
      "Requirement already satisfied: jsonlines>=1.2.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from bioc<3.0.0,>=2.0.0->flair->textattack) (4.0.0)\n",
      "Requirement already satisfied: intervaltree in c:\\users\\dell\\anaconda3\\lib\\site-packages (from bioc<3.0.0,>=2.0.0->flair->textattack) (3.1.0)\n",
      "Requirement already satisfied: botocore<1.39.0,>=1.38.26 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from boto3>=1.20.27->flair->textattack) (1.38.26)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from boto3>=1.20.27->flair->textattack) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.14.0,>=0.13.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from boto3>=1.20.27->flair->textattack) (0.13.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.4.0->textattack) (3.10.5)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\dell\\anaconda3\\lib\\site-packages (from ftfy>=6.1.0->flair->textattack) (0.2.5)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from gdown>=4.4.0->flair->textattack) (4.12.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from matplotlib->bert-score>=0.3.5->textattack) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from matplotlib->bert-score>=0.3.5->textattack) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from matplotlib->bert-score>=0.3.5->textattack) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from matplotlib->bert-score>=0.3.5->textattack) (1.4.4)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from matplotlib->bert-score>=0.3.5->textattack) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from matplotlib->bert-score>=0.3.5->textattack) (3.1.2)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from transformers[sentencepiece]<5.0.0,>=4.25.0->flair->textattack) (0.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.4.0->textattack) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.4.0->textattack) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.4.0->textattack) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.4.0->textattack) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.4.0->textattack) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.4.0->textattack) (1.11.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from transformers[sentencepiece,torch]<5.0,>=4.1->transformer-smaller-training-vocab>=0.2.3->flair->textattack) (1.7.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from beautifulsoup4->gdown>=4.4.0->flair->textattack) (2.5)\n",
      "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from intervaltree->bioc<3.0.0,>=2.0.0->flair->textattack) (2.4.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests[socks]->gdown>=4.4.0->flair->textattack) (1.7.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install textattack tensorflow pandas numpy scikit-learn nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sentiment                                               text\n",
      "0          0  is upset that he can't update his Facebook by ...\n",
      "1          0  @Kenichan I dived many times for the ball. Man...\n",
      "2          0    my whole body feels itchy and like its on fire \n",
      "3          0  @nationwideclass no, it's not behaving at all....\n",
      "4          0                      @Kwesidei not the whole crew \n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Load and preprocess data (unchanged)\n",
    "df = pd.read_csv(\"../data/training.1600000.processed.noemoticon.csv\", encoding=\"latin-1\")\n",
    "df = df.iloc[:, [0, 5]]\n",
    "df.columns = ['sentiment', 'text']\n",
    "df.drop_duplicates(inplace=True)\n",
    "df['sentiment'] = df['sentiment'].map({0: 'negatif', 4: 'positif'})\n",
    "df['sentiment'] = df['sentiment'].map({'negatif': 0, 'positif': 1})  # Convert to binary labels\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Text preprocessing\n",
    "max_words = 10000  # Maximum number of words in vocabulary\n",
    "max_len = 100      # Maximum sequence length\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(df['text'])\n",
    "sequences = tokenizer.texts_to_sequences(df['text'])\n",
    "X = pad_sequences(sequences, maxlen=max_len)\n",
    "y = df['sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load my LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('../models/best_model.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Adversarial Examples with TextAttack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Adversarial Training with FGM\n",
    "def fgm_perturbation(model, x, y, epsilon=0.1):\n",
    "    \"\"\"\n",
    "    Generate adversarial examples using Fast Gradient Method (FGM).\n",
    "    Perturbs the embeddings of the input sequences.\n",
    "    \"\"\"\n",
    "    # Ensure model is in training mode\n",
    "    model.trainable = True\n",
    "    \n",
    "    # Get the embedding layer\n",
    "    embedding_layer = model.get_layer(index=0)\n",
    "    \n",
    "    # Create a model that outputs embeddings\n",
    "    embedding_model = tf.keras.Model(inputs=model.input, \n",
    "                                   outputs=embedding_layer.output)\n",
    "    \n",
    "    # Get embeddings for the input\n",
    "    embeddings = embedding_model(x)\n",
    "    \n",
    "    # Compute gradients of loss with respect to embeddings\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(embeddings)\n",
    "        preds = model(x)\n",
    "        loss = tf.keras.losses.binary_crossentropy(y, preds)\n",
    "    \n",
    "    # Calculate gradients\n",
    "    gradients = tape.gradient(loss, embeddings)\n",
    "    \n",
    "    # Normalize gradients (sign of gradients for FGM)\n",
    "    gradients_sign = tf.sign(gradients)\n",
    "    \n",
    "    # Apply perturbation to embeddings\n",
    "    adv_embeddings = embeddings + epsilon * gradients_sign\n",
    "    \n",
    "    # Create a model to convert perturbed embeddings back to predictions\n",
    "    adv_model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(max_len, model.get_layer(index=0).output_dim)),\n",
    "        *model.layers[1:]  # Include all layers after the embedding layer\n",
    "    ])\n",
    "    \n",
    "    # Get predictions for adversarial examples\n",
    "    adv_preds = adv_model(adv_embeddings)\n",
    "    \n",
    "    return adv_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom fine-tuning loop with adversarial training\n",
    "def fine_tune_with_adversarial(model, X_train, y_train, X_test, y_test, epochs=3, batch_size=32, epsilon=0.1):\n",
    "    # Use a smaller learning rate for fine-tuning\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', \n",
    "                  metrics=['accuracy', 'precision', 'recall'])\n",
    "    \n",
    "    history = {'accuracy': [], 'val_accuracy': [], 'loss': [], 'val_loss': []}\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(f'Fine-Tuning Epoch {epoch+1}/{epochs}')\n",
    "        batch_losses = []\n",
    "        batch_accuracies = []\n",
    "        \n",
    "        # Iterate over batches\n",
    "        for i in range(0, len(X_train), batch_size):\n",
    "            x_batch = X_train[i:i+batch_size]\n",
    "            y_batch = y_train[i:i+batch_size]\n",
    "            \n",
    "            # Standard training step\n",
    "            with tf.GradientTape() as tape:\n",
    "                preds = model(x_batch, training=True)\n",
    "                loss = tf.keras.losses.binary_crossentropy(y_batch, preds)\n",
    "            \n",
    "            gradients = tape.gradient(loss, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "            \n",
    "            # Adversarial training step\n",
    "            adv_preds = fgm_perturbation(model, x_batch, y_batch, epsilon)\n",
    "            with tf.GradientTape() as tape:\n",
    "                adv_loss = tf.keras.losses.binary_crossentropy(y_batch, adv_preds)\n",
    "            \n",
    "            adv_gradients = tape.gradient(adv_loss, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(adv_gradients, model.trainable_variables))\n",
    "            \n",
    "            # Compute metrics\n",
    "            batch_losses.append(loss.numpy().mean())\n",
    "            batch_accuracies.append(tf.keras.metrics.binary_accuracy(y_batch, preds).numpy().mean())\n",
    "        \n",
    "        # Validation step\n",
    "        val_pred = model(X_test, training=False)\n",
    "        val_loss = tf.keras.losses.binary_crossentropy(y_test, val_pred).numpy().mean()\n",
    "        val_accuracy = tf.keras.metrics.binary_accuracy(y_test, val_pred).numpy().mean()\n",
    "        \n",
    "        # Log metrics\n",
    "        history['loss'].append(np.mean(batch_losses))\n",
    "        history['accuracy'].append(np.mean(batch_accuracies))\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_accuracy'].append(val_accuracy)\n",
    "        \n",
    "        print(f'Loss: {history[\"loss\"][-1]:.4f}, Accuracy: {history[\"accuracy\"][-1]:.4f}, '\n",
    "              f'Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 1/3\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Arguments `target` and `output` must have the same rank (ndim). Received: target.shape=(32,), output.shape=(32, 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Cell 6: Fine-tune the model with adversarial training\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m fine_tune_with_adversarial(model, X_train, y_train, X_test, y_test, \n\u001b[0;32m      3\u001b[0m                                     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, epsilon\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n",
      "Cell \u001b[1;32mIn[27], line 23\u001b[0m, in \u001b[0;36mfine_tune_with_adversarial\u001b[1;34m(model, X_train, y_train, X_test, y_test, epochs, batch_size, epsilon)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[0;32m     22\u001b[0m     preds \u001b[38;5;241m=\u001b[39m model(x_batch, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 23\u001b[0m     loss \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mbinary_crossentropy(y_batch, preds)\n\u001b[0;32m     25\u001b[0m gradients \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(loss, model\u001b[38;5;241m.\u001b[39mtrainable_variables)\n\u001b[0;32m     26\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mapply_gradients(\u001b[38;5;28mzip\u001b[39m(gradients, model\u001b[38;5;241m.\u001b[39mtrainable_variables))\n",
      "File \u001b[1;32mc:\\Users\\dell\\anaconda3\\Lib\\site-packages\\keras\\src\\losses\\losses.py:2302\u001b[0m, in \u001b[0;36mbinary_crossentropy\u001b[1;34m(y_true, y_pred, from_logits, label_smoothing, axis)\u001b[0m\n\u001b[0;32m   2298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m label_smoothing:\n\u001b[0;32m   2299\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m y_true \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m label_smoothing) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m label_smoothing\n\u001b[0;32m   2301\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mmean(\n\u001b[1;32m-> 2302\u001b[0m     ops\u001b[38;5;241m.\u001b[39mbinary_crossentropy(y_true, y_pred, from_logits\u001b[38;5;241m=\u001b[39mfrom_logits),\n\u001b[0;32m   2303\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   2304\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\dell\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\nn.py:1795\u001b[0m, in \u001b[0;36mbinary_crossentropy\u001b[1;34m(target, output, from_logits)\u001b[0m\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors((target, output)):\n\u001b[0;32m   1792\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m BinaryCrossentropy(from_logits\u001b[38;5;241m=\u001b[39mfrom_logits)\u001b[38;5;241m.\u001b[39msymbolic_call(\n\u001b[0;32m   1793\u001b[0m         target, output\n\u001b[0;32m   1794\u001b[0m     )\n\u001b[1;32m-> 1795\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mbinary_crossentropy(\n\u001b[0;32m   1796\u001b[0m     target, output, from_logits\u001b[38;5;241m=\u001b[39mfrom_logits\n\u001b[0;32m   1797\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\dell\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py:767\u001b[0m, in \u001b[0;36mbinary_crossentropy\u001b[1;34m(target, output, from_logits)\u001b[0m\n\u001b[0;32m    764\u001b[0m output \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(output)\n\u001b[0;32m    766\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(target\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(output\u001b[38;5;241m.\u001b[39mshape):\n\u001b[1;32m--> 767\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    768\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArguments `target` and `output` must have the same rank \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    769\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(ndim). Received: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    770\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, output.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    771\u001b[0m     )\n\u001b[0;32m    772\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e1, e2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(target\u001b[38;5;241m.\u001b[39mshape, output\u001b[38;5;241m.\u001b[39mshape):\n\u001b[0;32m    773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e1 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m e2 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m e1 \u001b[38;5;241m!=\u001b[39m e2:\n",
      "\u001b[1;31mValueError\u001b[0m: Arguments `target` and `output` must have the same rank (ndim). Received: target.shape=(32,), output.shape=(32, 2)"
     ]
    }
   ],
   "source": [
    "# Cell 6: Fine-tune the model with adversarial training\n",
    "history = fine_tune_with_adversarial(model, X_train, y_train, X_test, y_test, \n",
    "                                    epochs=3, batch_size=32, epsilon=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Save the fine-tuned model\n",
    "model.save('../models/best_model_adversarial.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Plot training history (unchanged)\n",
    "plt.plot(history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.plot(history['loss'], label='Train Loss')\n",
    "plt.plot(history['val_loss'], label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Evaluate the fine-tuned model (unchanged)\n",
    "results = model.evaluate(X_test, y_test, batch_size=32)\n",
    "print(f\"Test Loss: {results[0]:.4f}\")\n",
    "print(f\"Test Accuracy: {results[1]:.4f}\")\n",
    "print(f\"Test Precision: {results[2]:.4f}\")\n",
    "print(f\"Test Recall: {results[3]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Test robustness on adversarial examples\n",
    "adv_test_preds = fgm_perturbation(model, X_test, y_test, epsilon=0.1)\n",
    "adv_test_accuracy = tf.keras.metrics.binary_accuracy(y_test, adv_test_preds).numpy().mean()\n",
    "print(f\"Adversarial Test Accuracy: {adv_test_accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
