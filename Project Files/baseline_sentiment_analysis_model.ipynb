{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Sentiment Analysis Model\n",
    "\n",
    "This notebook implements a baseline sentiment analysis model using TF-IDF features and Logistic Regression. It serves as a benchmark for comparison with BERT and robustness testing. Adapted from `baseline_model.py` to run in Google Colab, using preprocessed data stored on Google Drive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports\n",
    "\n",
    "Mount Google Drive, install dependencies, and import required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Install necessary libraries\n",
    "!pip install scikit-learn joblib matplotlib seaborn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Configuration\n",
    "DATA_DIR = Path('/content/drive/MyDrive/twitter_data')\n",
    "MODELS_DIR = DATA_DIR / 'models'\n",
    "RESULTS_DIR = DATA_DIR / 'results'\n",
    "BASELINE_CONFIG = {\n",
    "    'tfidf_max_features': 5000,\n",
    "    'tfidf_ngram_range': (1, 2),\n",
    "    'lr_C': 1.0,\n",
    "    'lr_max_iter': 1000\n",
    "}\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Create directories if they don't exist\n",
    "MODELS_DIR.mkdir(exist_ok=True)\n",
    "RESULTS_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Sentiment Model Class\n",
    "\n",
    "Define the `BaselineSentimentModel` class for TF-IDF + Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaselineSentimentModel:\n",
    "    \"\"\"\n",
    "    Baseline sentiment analysis model using TF-IDF features and Logistic Regression\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config=BASELINE_CONFIG):\n",
    "        \"\"\"\n",
    "        Initialize the baseline model with configuration\n",
    "        \n",
    "        Args:\n",
    "            config (dict): Model configuration parameters\n",
    "        \"\"\"\n",
    "        self.config = config\n",
    "        self.model = None\n",
    "        self.is_trained = False\n",
    "        \n",
    "        # Create the pipeline\n",
    "        self.pipeline = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(\n",
    "                max_features=config['tfidf_max_features'],\n",
    "                ngram_range=config['tfidf_ngram_range'],\n",
    "                stop_words='english',\n",
    "                lowercase=True\n",
    "            )),\n",
    "            ('classifier', LogisticRegression(\n",
    "                C=config['lr_C'],\n",
    "                max_iter=config['lr_max_iter'],\n",
    "                random_state=RANDOM_STATE\n",
    "            ))\n",
    "        ])\n",
    "        \n",
    "        logger.info(\"Baseline model initialized\")\n",
    "    \n",
    "    def train(self, X_train, y_train, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        Train the baseline model\n",
    "        \n",
    "        Args:\n",
    "            X_train (array-like): Training texts\n",
    "            y_train (array-like): Training labels\n",
    "            X_val (array-like): Validation texts (optional)\n",
    "            y_val (array-like): Validation labels (optional)\n",
    "            \n",
    "        Returns:\n",
    "            dict: Training history and validation scores\n",
    "        \"\"\"\n",
    "        logger.info(\"Training baseline model...\")\n",
    "        \n",
    "        # Fit the pipeline\n",
    "        self.pipeline.fit(X_train, y_train)\n",
    "        self.is_trained = True\n",
    "        \n",
    "        # Evaluate on training set\n",
    "        train_pred = self.pipeline.predict(X_train)\n",
    "        train_accuracy = accuracy_score(y_train, train_pred)\n",
    "        \n",
    "        results = {\n",
    "            'train_accuracy': train_accuracy,\n",
    "            'train_size': len(X_train)\n",
    "        }\n",
    "        \n",
    "        logger.info(f\"Training accuracy: {train_accuracy:.4f}\")\n",
    "        \n",
    "        # Evaluate on validation set if provided\n",
    "        if X_val is not None and y_val is not None:\n",
    "            val_pred = self.pipeline.predict(X_val)\n",
    "            val_accuracy = accuracy_score(y_val, val_pred)\n",
    "            results['val_accuracy'] = val_accuracy\n",
    "            logger.info(f\"Validation accuracy: {val_accuracy:.4f}\")\n",
    "        \n",
    "        self.model = self.pipeline\n",
    "        return results\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Make predictions on new data\n",
    "        \n",
    "        Args:\n",
    "            X (array-like): Input texts\n",
    "            \n",
    "        Returns:\n",
    "            array: Predicted labels\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before making predictions\")\n",
    "        \n",
    "        return self.pipeline.predict(X)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Get prediction probabilities\n",
    "        \n",
    "        Args:\n",
    "            X (array-like): Input texts\n",
    "            \n",
    "        Returns:\n",
    "            array: Prediction probabilities\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before making predictions\")\n",
    "        \n",
    "        return self.pipeline.predict_proba(X)\n",
    "    \n",
    "    def evaluate(self, X_test, y_test, save_results=True):\n",
    "        \"\"\"\n",
    "        Comprehensive model evaluation\n",
    "        \n",
    "        Args:\n",
    "            X_test (array-like): Test texts\n",
    "            y_test (array-like): Test labels\n",
    "            save_results (bool): Whether to save evaluation plots\n",
    "            \n",
    "        Returns:\n",
    "            dict: Evaluation metrics\n",
    "        \"\"\"\n",
    "        logger.info(\"Evaluating baseline model...\")\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = self.predict(X_test)\n",
    "        y_pred_proba = self.predict_proba(X_test)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        report = classification_report(y_test, y_pred, output_dict=True)\n",
    "        \n",
    "        # Confusion matrix\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "        results = {\n",
    "            'accuracy': accuracy,\n",
    "            'precision': report['weighted avg']['precision'],\n",
    "            'recall': report['weighted avg']['recall'],\n",
    "            'f1_score': report['weighted avg']['f1-score'],\n",
    "            'confusion_matrix': cm.tolist(),\n",
    "            'classification_report': report\n",
    "        }\n",
    "        \n",
    "        logger.info(f\"Test accuracy: {accuracy:.4f}\")\n",
    "        logger.info(f\"Test F1-score: {results['f1_score']:.4f}\")\n",
    "        \n",
    "        # Save visualizations\n",
    "        if save_results:\n",
    "            self._save_evaluation_plots(cm, y_test, y_pred_proba)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _save_evaluation_plots(self, cm, y_test, y_pred_proba):\n",
    "        \"\"\"\n",
    "        Save evaluation plots and visualizations\n",
    "        \n",
    "        Args:\n",
    "            cm (array): Confusion matrix\n",
    "            y_test (array): True labels\n",
    "            y_pred_proba (array): Prediction probabilities\n",
    "        \"\"\"\n",
    "        # Create plots directory\n",
    "        plots_dir = RESULTS_DIR / 'baseline_plots'\n",
    "        plots_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        # 1. Confusion Matrix\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                   xticklabels=['Negative', 'Positive'],\n",
    "                   yticklabels=['Negative', 'Positive'])\n",
    "        plt.title('Baseline Model - Confusion Matrix')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(plots_dir / 'confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # 2. Prediction Confidence Distribution\n",
    "        plt.figure(figsize=(12, 5))\n",
    "        \n",
    "        # Subplot 1: Confidence for negative predictions\n",
    "        plt.subplot(1, 2, 1)\n",
    "        neg_confidence = y_pred_proba[y_test == 0][:, 0]\n",
    "        plt.hist(neg_confidence, bins=30, alpha=0.7, color='red', label='True Negative')\n",
    "        pos_confidence_neg = y_pred_proba[y_test == 1][:, 0]\n",
    "        plt.hist(pos_confidence_neg, bins=30, alpha=0.7, color='blue', label='True Positive')\n",
    "        plt.xlabel('Confidence for Negative Class')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.title('Confidence Distribution - Negative Class')\n",
    "        plt.legend()\n",
    "        \n",
    "        # Subplot 2: Confidence for positive predictions\n",
    "        plt.subplot(1, 2, 2)\n",
    "        neg_confidence_pos = y_pred_proba[y_test == 0][:, 1]\n",
    "        plt.hist(neg_confidence_pos, bins=30, alpha=0.7, color='red', label='True Negative')\n",
    "        pos_confidence = y_pred_proba[y_test == 1][:, 1]\n",
    "        plt.hist(pos_confidence, bins=30, alpha=0.7, color='blue', label='True Positive')\n",
    "        plt.xlabel('Confidence for Positive Class')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.title('Confidence Distribution - Positive Class')\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(plots_dir / 'confidence_distribution.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        logger.info(f\"Evaluation plots saved to {plots_dir}\")\n",
    "    \n",
    "    def get_feature_importance(self, top_n=20):\n",
    "        \"\"\"\n",
    "        Get the most important features (words) for each class\n",
    "        \n",
    "        Args:\n",
    "            top_n (int): Number of top features to return\n",
    "            \n",
    "        Returns:\n",
    "            dict: Top features for each class\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained first\")\n",
    "        \n",
    "        # Get feature names and coefficients\n",
    "        feature_names = self.pipeline.named_steps['tfidf'].get_feature_names_out()\n",
    "        coef = self.pipeline.named_steps['classifier'].coef_[0]\n",
    "        \n",
    "        # Get top positive and negative features\n",
    "        top_positive_idx = np.argsort(coef)[-top_n:][::-1]\n",
    "        top_negative_idx = np.argsort(coef)[:top_n]\n",
    "        \n",
    "        top_positive_features = [(feature_names[i], coef[i]) for i in top_positive_idx]\n",
    "        top_negative_features = [(feature_names[i], coef[i]) for i in top_negative_idx]\n",
    "        \n",
    "        return {\n",
    "            'positive_features': top_positive_features,\n",
    "            'negative_features': top_negative_features\n",
    "        }\n",
    "    \n",
    "    def save_model(self, model_path=None):\n",
    "        \"\"\"\n",
    "        Save the trained model\n",
    "        \n",
    "        Args:\n",
    "            model_path (str): Path to save the model\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before saving\")\n",
    "        \n",
    "        if model_path is None:\n",
    "            model_path = MODELS_DIR / 'baseline_model.pkl'\n",
    "        \n",
    "        model_data = {\n",
    "            'pipeline': self.pipeline,\n",
    "            'config': self.config,\n",
    "            'is_trained': self.is_trained\n",
    "        }\n",
    "        \n",
    "        joblib.dump(model_data, model_path)\n",
    "        logger.info(f\"Model saved to {model_path}\")\n",
    "    \n",
    "    def load_model(self, model_path=None):\n",
    "        \"\"\"\n",
    "        Load a previously trained model\n",
    "        \n",
    "        Args:\n",
    "            model_path (str): Path to the saved model\n",
    "        \"\"\"\n",
    "        if model_path is None:\n",
    "            model_path = MODELS_DIR / 'baseline_model.pkl'\n",
    "        \n",
    "        if not Path(model_path).exists():\n",
    "            raise FileNotFoundError(f\"Model file not found: {model_path}\")\n",
    "        \n",
    "        model_data = joblib.load(model_path)\n",
    "        self.pipeline = model_data['pipeline']\n",
    "        self.config = model_data['config']\n",
    "        self.is_trained = model_data['is_trained']\n",
    "        self.model = self.pipeline\n",
    "        \n",
    "        logger.info(f\"Model loaded from {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Execution\n",
    "\n",
    "Load preprocessed data, train, and evaluate the baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed data\n",
    "data_path = DATA_DIR / 'processed_splits.pkl'\n",
    "if not data_path.exists():\n",
    "    logger.error(f\"Processed data not found: {data_path}\")\n",
    "    logger.info(\"Please run data_preprocessing.ipynb first to generate the processed data\")\n",
    "    raise FileNotFoundError(f\"Processed data not found: {data_path}\")\n",
    "\n",
    "data = joblib.load(data_path)\n",
    "X_train = data['X_train']\n",
    "X_val = data['X_val']\n",
    "X_test = data['X_test']\n",
    "y_train = data['y_train']\n",
    "y_val = data['y_val']\n",
    "y_test = data['y_test']\n",
    "\n",
    "logger.info(\"Loaded preprocessed data splits\")\n",
    "\n",
    "# Initialize and train model\n",
    "baseline_model = BaselineSentimentModel()\n",
    "\n",
    "# Train the model\n",
    "train_results = baseline_model.train(X_train, y_train, X_val, y_val)\n",
    "\n",
    "# Evaluate on test set\n",
    "test_results = baseline_model.evaluate(X_test, y_test)\n",
    "\n",
    "# Get feature importance\n",
    "feature_importance = baseline_model.get_feature_importance()\n",
    "\n",
    "# Print top features\n",
    "logger.info(\"\\nTop features for POSITIVE sentiment:\")\n",
    "for feature, coef in feature_importance['positive_features'][:10]:\n",
    "    logger.info(f\"  {feature}: {coef:.4f}\")\n",
    "\n",
    "logger.info(\"\\nTop features for NEGATIVE sentiment:\")\n",
    "for feature, coef in feature_importance['negative_features'][:10]:\n",
    "    logger.info(f\"  {feature}: {coef:.4f}\")\n",
    "\n",
    "# Save model and results\n",
    "baseline_model.save_model()\n",
    "\n",
    "# Save results\n",
    "all_results = {\n",
    "    'train_results': train_results,\n",
    "    'test_results': test_results,\n",
    "    'feature_importance': feature_importance\n",
    "}\n",
    "\n",
    "joblib.dump(all_results, RESULTS_DIR / 'baseline_results.pkl')\n",
    "\n",
    "logger.info(\"Baseline model training and evaluation completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage Instructions\n",
    "\n",
    "1. **Prerequisites**:\n",
    "   - Ensure the preprocessed data file (`processed_splits.pkl`) is available in the `twitter_data` folder on your Google Drive, generated by running `data_preprocessing.ipynb`.\n",
    "2. **Run the Notebook**:\n",
    "   - Execute all cells in sequence. The first cell mounts Google Drive and installs dependencies.\n",
    "   - The notebook loads the preprocessed data, trains the TF-IDF + Logistic Regression model, evaluates it, and saves the results.\n",
    "3. **Outputs**:\n",
    "   - The trained model is saved as `baseline_model.pkl` in the `twitter_data/models` folder.\n",
    "   - Evaluation results are saved as `baseline_results.pkl` in the `twitter_data/results` folder.\n",
    "   - Plots (confusion matrix and confidence distribution) are saved in the `twitter_data/results/baseline_plots` folder.\n",
    "4. **Notes**:\n",
    "   - The model uses a TF-IDF vectorizer with up to 5000 features and bigrams, and a Logistic Regression classifier with C=1.0. Adjust these in `BASELINE_CONFIG` if needed.\n",
    "   - The notebook logs training, validation, and test accuracies, as well as the top 10 features for positive and negative sentiments.\n",
    "   - This model is lightweight and does not require a GPU, making it suitable for CPU-only Colab runtimes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
